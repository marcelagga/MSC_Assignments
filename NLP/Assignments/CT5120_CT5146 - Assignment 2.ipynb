{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC-LZ20S_WUr"
   },
   "source": [
    "# Assignment 2: Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9xqCFJBv_WUt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Name: Marcel Aguilar Garcia\n",
    "#Student ID: 20235620\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq8sr9x17KhU"
   },
   "source": [
    "## Task 1: Named Entity Annotation (10 Marks)\n",
    "\n",
    "Using the IOB tagging scheme annotate all of the named entities (PERson, LOCation, ORGanisation, TIME) in the following sentence:\n",
    "\n",
    "*Wayne Rooney is a professional footballer from England who last played for Major League Soccer club D.C. United and will join Derby County in January 2020.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htlSW1ad81D-"
   },
   "source": [
    "Edit this cell and write your annotation below the line. (Note that you don't have to write code for this task, you have to annotate it manually)\n",
    "\n",
    "---\n",
    "Wayne [B-PER]  Rooney [I-PER] is [O] a [O] professional [O] footballer [O] from [O] England [B-LOC] who [O] last [O] played [O] for [O] Major [B-ORG] League [I-ORG] Soccer [I-ORG] club [I-ORG] D.C.[I-ORG] United [I-ORG] and [O] will [O] join [O] Derby [B-ORG] County [I-ORG] in January [B-TIME] 2020 [I-TIME]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZNmDWxj-V-J"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### For subsequent tasks in this assignment, you will work with the documents in `football_players.txt` to perform various information extraction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "V9YE4n6u7olU"
   },
   "outputs": [],
   "source": [
    "# Download the text file (uncomment the line below in this cell, if not already downloaded from Blackboard)\n",
    "# !curl \"https://ideone.com/plain/OvwDXZ\" > football_players.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpSaij2b73Vj"
   },
   "source": [
    " Read all the documents from `football_players.txt` into a list called `docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qteh89cs7q4x"
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "docs = open(\"football_players.txt\",encoding=\"utf8\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCEJrJ-p_WU1"
   },
   "source": [
    "## Task 2 (10 Marks)\n",
    "Write a function that takes a document and returns a list of sentences with part-of-speech tags.\n",
    "\n",
    "Please keep in mind that the expected output is a list within a list as shown below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO7Fyfq7DYxW"
   },
   "source": [
    "Hint: For this task you need to perform three steps:\n",
    "1. Sentence Segmentation\n",
    "1. Word Tokenization\n",
    "1. Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U3MCJIcR_WU2"
   },
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    sents = nltk.sent_tokenize(document)\n",
    "    for num,sent in enumerate(sents):\n",
    "        sents[num] = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-E04CUNb_WU6"
   },
   "source": [
    "Run the cell below to verify your result for the second sentence in the first document.\n",
    "Expected output: \n",
    "`[('He', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('forward', 'NN'), ('and', 'CC'), ('serves', 'NNS'), ('as', 'IN'), ('captain', 'NN'), ('for', 'IN'), ('Portugal', 'NNP'), ('.', '.')]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R30taRgf_WU6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('forward', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('serves', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('captain', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('Portugal', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc = docs[0]\n",
    "tagged_sentences = ie_preprocess(first_doc)\n",
    "tagged_sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYTwrZId_WU_"
   },
   "source": [
    "## Task 3 (20 Marks)\n",
    "Write a function that takes a list of tokens with POS tags for a sentence and returns a list of named entities (NE). \n",
    "\n",
    "Hint: Use `binary = True` while calling NE chunk function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5fC0iqJJ_WU_"
   },
   "outputs": [],
   "source": [
    "def find_named_entities(sent):\n",
    "    named_entities = []\n",
    "    tree = nltk.ne_chunk(sent, binary=True)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'NE':\n",
    "            entity = \"\"\n",
    "            for leaf in subtree.leaves():\n",
    "                entity = entity + leaf[0] + \" \"\n",
    "            named_entities.append(entity.strip())\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td5yJ8cgFScx"
   },
   "source": [
    "Run the cell below to verify your result for the first sentence in the first document.\n",
    "Expected output: `['Cristiano Ronaldo', 'Santos Aveiro', 'ComM', 'GOIH', 'Portuguese', 'Portuguese', 'Spanish', 'Real Madrid', 'Portugal']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FijjdAPWFsp2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cristiano Ronaldo',\n",
       " 'Santos Aveiro',\n",
       " 'ComM',\n",
       " 'GOIH',\n",
       " 'Portuguese',\n",
       " 'Portuguese',\n",
       " 'Spanish',\n",
       " 'Real Madrid',\n",
       " 'Portugal']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences = ie_preprocess(docs[0])\n",
    "find_named_entities(tagged_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHMp7xtK_WVE"
   },
   "source": [
    "## Task 4 (5 Marks)\n",
    "\n",
    "Implement the `find_all_named_entities` function below to find **all** NEs in a given document.\n",
    "\n",
    "Hint: Use `find_named_entities` implemented above for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TwFlzQx4_WVF"
   },
   "outputs": [],
   "source": [
    "def find_all_named_entities(doc):\n",
    "    named_entities = []\n",
    "    for sent in ie_preprocess(doc):\n",
    "        named_entities+=find_named_entities(sent)\n",
    "    return named_entities  # return a flat list and not a list of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdM0-LZlJy4u"
   },
   "source": [
    "How many named entities did you find in the first document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_ajmnnOqJ8V6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56 entities in the first document\n"
     ]
    }
   ],
   "source": [
    "#The number of entities in the first document is 56. I could have checked the unique number of \n",
    "#entities by converting the list to a set \n",
    "number_of_named_entities = len(find_all_named_entities(docs[0]))\n",
    "print(f'There are {number_of_named_entities} entities in the first document' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2AzD9MVNIx2"
   },
   "source": [
    "## Task 5 (5 Marks)\n",
    "\n",
    "Find named entities across **all** documents in `football_players.txt`, and save the result into a single flat list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YULMcK1-NSR9"
   },
   "outputs": [],
   "source": [
    "all_named_entities = []\n",
    "for doc in docs:\n",
    "    all_named_entities+=find_all_named_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaM9Cs9zNGM2"
   },
   "source": [
    "How many named entities did you find across all documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jCNIrC_SNpHQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 380 entities in the first document\n"
     ]
    }
   ],
   "source": [
    "#The total number of entities across all documents is 380. I could have checked the unique number of \n",
    "#entities by converting the list to a set first\n",
    "total_number_of_named_entities = len(all_named_entities)\n",
    "print(f'There are {total_number_of_named_entities} entities in the first document' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7-ma9lJ_WVJ"
   },
   "source": [
    "## Task 6 (40 Marks)\n",
    "\n",
    "Write functions to extract the name of the player, country of origin and date of birth as well as the following relations: team(s) of the player and position(s) of the player.\n",
    "\n",
    "Hint: Use the `re.compile()` function to create the extraction patterns.\n",
    "\n",
    "Reference: https://docs.python.org/3/howto/regex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tbaFyiah_WVK"
   },
   "outputs": [],
   "source": [
    "#Returns a string with the full name of the player in the document.\n",
    "#The name is always in the first line, therefore I will focus on that line.\n",
    "#While usually I would expect each word of the name to be 'NNP', \n",
    "#some names contain 'FW' and 'NN' (possibly for being non English names).\n",
    "#I am returning a sequence of words tagged as 'NNP','NN' and 'FW' from the first line\n",
    "#of the document. Note that to simplify I am ignoring symbols such as '', \n",
    "#used to denote nicknames\n",
    "\n",
    "def name_of_the_player(doc):\n",
    "    tagged_sentences = ie_preprocess(docs[n])[0]\n",
    "    name = \"\"\n",
    "    for word,tag in tagged_sentences:\n",
    "        if tag in ['NNP','NN','FW']:\n",
    "            name += word + \" \"\n",
    "        elif tag in ['\\'\\'','``']:\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "    return [name.strip()][0]\n",
    "\n",
    "#Returns the nationality of the player in the document.\n",
    "#While the nationality should just always be JJ, in some cases is being tagged as 'NNP'. \n",
    "#Using Regular Expressions I am extracting words that are after'is a', 'is an'\n",
    "#The intersection of JJs and NNPs on the text together with the list of words \n",
    "#given by regular expressions gives the nationality or country of origin of the player\n",
    "#Note that I could have return a country such as Ireland instead of a nationality such as Irish\n",
    "#by defining a list of all countries in the function and returning the one that matches the root\n",
    "#of the nationality. However, I have decided to keep it simple.\n",
    "\n",
    "def country_of_origin(doc):\n",
    "    p_country = re.compile(r'is\\s(a|an)\\s([A-z]\\w+)')\n",
    "    pattern_candidates = [groups[1] for groups in re.findall(p_country, doc)]\n",
    "    tag_candidates = [word for (word,tag) in nltk.pos_tag(nltk.word_tokenize(doc)) if tag in ['NNP','JJ']]\n",
    "    return [word for word in pattern_candidates if word in tag_candidates][0]\n",
    "\n",
    "#Returns a string with the date of birth of the player in the document.\n",
    "#Day can be expressed as D or DD depending on the number of digits. \n",
    "#Month is a string given by the name of the month (e.g March).\n",
    "#Year is expressed as a four digit number YYYY.\n",
    "#I have used Regular Expressions to return strings that are matching this pattern\n",
    "#Note that I have given a bit of flexibility into the format. As if new descriptions are added,\n",
    "#the date of birth could be in slightly different format.\n",
    "\n",
    "def date_of_birth(doc):\n",
    "    p_date = re.compile(r'born\\s([0-9]{1,2} \\b[Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec]\\w+ [0-9]{2,4})')\n",
    "    return re.findall(p_date, doc)[0] \n",
    "\n",
    "#Returns a list with the full name of teams where the player from the document is currently playing. \n",
    "#I have used regular expressions to retrieve words after 'who plays for...' or 'ambassador for...'.\n",
    "#After examining the name of the teams, the words on the name are 'JJ' (e.g when refering to a country),'NN' and 'NNP'.\n",
    "#As national teams are called 'The {Country} national team' if the word'the' is found to be part of the name,\n",
    "#I will be adding it\n",
    "#In case of having multiple teams, 'CC' will be used to keep adding words in the list.\n",
    "#Note that if a player does not have any team at the present (e.g retired), I will return a default string:\n",
    "#'No current team'. The reason for that is that I want my solution to be consistent accross all players. If I am returning\n",
    "#previous teams of the player, then I should be doing that for all of them. I like my solution more.\n",
    " \n",
    "def team_of_the_player(doc):\n",
    "    p_team = re.compile(r'(ambassador|who\\splay[a-z]*\\s)(.*?)for\\s(.*?)[.]')\n",
    "    all_candidates = re.findall(p_team, doc)\n",
    "    team = ['']\n",
    "    if len(all_candidates) > 0:\n",
    "        tagged_sentences = ie_preprocess(all_candidates[0][2])[0]\n",
    "        count = 0\n",
    "        for word,tag in tagged_sentences:\n",
    "            if tag in ['JJ','NN','NNP'] or word.lower() == 'the':\n",
    "                team[count]+=word+' '\n",
    "            elif len(team[0]) == 0: pass\n",
    "            elif len(team[0]) > 0 and tag != 'CC': break\n",
    "            else:\n",
    "                count += 1\n",
    "                team.append('')              \n",
    "        return [t.strip() for t in team]\n",
    "    else:\n",
    "        return ['No current team']\n",
    "\n",
    "\n",
    "#Returns a list with all positions of the player in the document\n",
    "#I will not go with too much detail as I have followed the exact idea than the previous function\n",
    "\n",
    "def position_of_the_player(doc):\n",
    "    p_position = re.compile(r'(\\sis|\\sas)\\s(a|an)\\s([a-z]\\w+(.*?)[.])')\n",
    "    all_candidates = re.findall(p_position, doc)\n",
    "    football_positions = ['']\n",
    "    if len(all_candidates) > 0:\n",
    "        tagged_sentences = ie_preprocess(re.findall(p_position, doc)[0][2])[0]\n",
    "        count = 0\n",
    "        for word,syntax in tagged_sentences:\n",
    "            if syntax in ['JJ','VBG','NN','NNP','RB']:\n",
    "                football_positions[count]+=word+' '\n",
    "            elif len(football_positions[0]) == 0: pass\n",
    "            elif len(football_positions[0]) > 0 and word == 'or':\n",
    "                count += 1\n",
    "                football_positions.append('')                \n",
    "            elif len(football_positions[0]) > 0:\n",
    "                break\n",
    "        return [p.strip() for p in football_positions]\n",
    "\n",
    "#My functions return the correct answer for all the players, additionally I have done a quick test \n",
    "#by using the first option given by each function to see that the following string is correct:\n",
    "\n",
    "# for n in range(10):\n",
    "#     name = name_of_the_player(docs[n])\n",
    "#     country = country_of_origin(docs[n])\n",
    "#     date_birth = date_of_birth(docs[n])\n",
    "#     team = team_of_the_player(docs[n])\n",
    "#     position = position_of_the_player(docs[n])\n",
    "#     print(f'{name} is {country}. He was born in {date_birth}. He currently plays for {team} and his position is {position}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-CNrMM5_WVO"
   },
   "source": [
    "Execute the cell below to verify the `date_of_birth` function for the third player. Expected output `5 February 1992`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jpeKE1u9_WVP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 February 1992'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_of_birth(docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3VtWxBr_WVZ"
   },
   "source": [
    "## Task 6 (10 Marks)\n",
    "Identify one other relation (besides team and player) and write a function to extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TR0GZrUB_WVa"
   },
   "outputs": [],
   "source": [
    "#Returns a list with the different language pronunciations of the name of the player\n",
    "#If there is none (e.g English name), it returns a default string 'It's an English name\n",
    "#Each pronunciation will be a tuple (language,pronunciation)\n",
    "\n",
    "def name_pronunciation(doc):\n",
    "    p_pronun = re.compile(r'([A-z]\\w+)(\\spronunciation)*:\\s\\[(.*?)\\]([\\s,])*')\n",
    "    candidates = re.findall(p_pronun, doc)\n",
    "    if len(candidates) > 0: \n",
    "        return [(c[0],c[2]) for c in candidates]\n",
    "    else: \n",
    "        return ['Its an English name']\n",
    "    \n",
    "# Again, the function has been manually tested by using\n",
    "# for n in range(10):\n",
    "#     print(name_pronunciation(docs[n]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 2.ipynb",
   "provenance": [
    {
     "file_id": "1EXXdimBbQY8nnqIs5hBXdG68r2hsk7HS",
     "timestamp": 1604940588321
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
